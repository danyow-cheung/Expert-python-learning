# Concurrency
並發性及其表現形式之一——並行處理——是軟件工程領域最廣泛的主題之一。 本書的大部分章節也涵蓋了廣闊的領域，幾乎所有章節都可以作為單獨一本書的大主題。 但是並發這個話題本身就非常龐大，它可以佔據幾十個位置，我們仍然無法討論它的所有重要方面和模型。

這就是為什麼我不會試圖愚弄你，並且從一開始就聲明我們幾乎不會觸及這個話題的表面。 本章的目的是展示為什麼你的應用程序可能需要並發，何時使用它，以及你可能在 Python 中使用的最重要的並發模型是什麼：
- 多線程threading
- 多processing
- 異步編程asynchronous programming

我們還將討論允許您在代碼中實現這些模型的一些語言特性、內置模塊和第三方包。 但我們不會詳細介紹它們。 將本章的內容作為您進一步研究和閱讀的切入點。 它在這裡指導您了解基本思想並幫助您決定是否真的需要並發，如果需要，哪種方法最適合您的需要。

## Why concurrency
而第二個問題的答案可能會讓一些曾經認為這是並行處理同義詞的人感到驚訝。 但並發性與並行性不同。 並發不是應用程序實現的問題，而只是程序、算法或問題的屬性。 並行性只是解決並發問題的可能方法之一。
萊斯利·蘭波特 (Leslie Lamport) 在他 1976 年發表的分佈式系統中的時間、時鐘和事件排序論文中說：
“如果兩個事件都不能因果影響另一個，則兩個事件是同時發生的。”


通過將事件外推到程序、算法或問題，如果某事物可以完全或部分分解為與順序無關的組件（單元），我們可以說它是並發的。 這些單元可以相互獨立處理，處理順序不影響最終結果。 這意味著它們也可以同時或併行處理。 如果我們以這種方式處理信息，那麼我們確實是在進行並行處理。 但這仍然不是強制性的。

## Multithreading
線程通常被開發人員認為是一個複雜的話題。 雖然這個說法完全正確，但 Python 提供了高級類和函數來簡化線程的使用。 CPython 的線程實現帶有一些不方便的細節，使它們不如其他語言有用。 對於您可能想要解決的一些集合問題，它們仍然完全沒問題，但不像 C 或 Java 那樣多。 在本節中，我們將討論 CPython 中多線程的局限性，以及 Python 線程作為可行解決方案的常見並發問題。

### What is multithreading
線程是執行線程的縮寫。 程序員可以將他或她的工作分成同時運行並共享相同內存上下文的線程。 除非你的代碼依賴第三方資源，否則多線程不會在單核處理器上加速，甚至會增加一些線程管理的開銷。 多線程將受益於多處理器或多核機器，並將在每個 CPU 內核上並行執行每個線程，從而使程序更快。 請注意，這是適用於大多數編程語言的一般規則。 在 Python 中，多核 CPU 上多線程的性能優勢有一些限制，但我們將在稍後討論。 為簡單起見，我們現在假設此陳述是正確的。


線程之間共享相同的上下文這一事實意味著您必須保護數據免受並發訪問。 如果兩個線程在沒有任何保護的情況下更新相同的數據，就會出現競爭條件。 這稱為競爭風險，由於每個線程運行的代碼對數據狀態做出錯誤假設，可能會出現意外結果。

鎖定機制有助於保護數據，線程編程一直是確保線程以安全方式訪問資源的問題。 這可能非常困難，線程編程通常會導致難以調試的錯誤，因為它們很難重現。 最糟糕的問題是，由於糟糕的代碼設計，兩個線程鎖定一個資源並試圖獲取另一個線程鎖定的資源。 他們將永遠等待彼此。 這稱為死鎖，很難調試。 可重入鎖通過確保線程不會因嘗試鎖定資源兩次而被鎖定，對此有所幫助。

多線程通常在系統內核級別得到支持。 當機器只有一個單核處理器時，系統使用時間片機制。 在這裡，CPU 從一個線程切換到另一個線程的速度如此之快，以至於有一種線程同時運行的錯覺。 這也是在處理級別完成的。 沒有多個處理單元的並行顯然是虛擬的，在這種硬件上運行多個線程不會提高性能。 無論如何，有時用
線程，即使它必須在單個內核上執行，我們稍後會看到一個可能的用例。

當您的執行環境有多個處理器或多個 CPU 內核用於配置時，一切都會改變。 即使使用時間片，進程和線程也會分佈在 CPU 之間，從而提供更快地運行程序的能力。

### How python deals with threads
與其他一些語言不同，Python 使用多個內核級線程，每個線程都可以運行任何解釋器級線程。 但是語言的標準實現——CPython——有一個主要的限制，使得線程在許多情況下不太可用。 所有訪問 Python 對象的線程都由一個全局鎖序列化。 這樣做是因為許多解釋器內部結構以及第三方 C 代碼都不是線程安全的，需要加以保護。

這種機制稱為全局解釋器鎖（GIL）
刪除 GIL 是一個偶爾出現在 python-dev 電子郵件列表中的話題，並且被開發人員多次提出。 遺憾的是，直到這個時候，還沒有人能夠提供一個合理而簡單的解決方案來讓我們擺脫這一限制。 我們極不可能很快看到這方面的任何進展。 更安全的假設是 GIL 將永遠留在 CPython 中。 所以我們需要學習如何忍受它。

這意味著，多個線程可以並行地進行 I/O 操作或執行某些第三方擴展中的 C 代碼。

對於使用外部資源或涉及 C 代碼的非純代碼塊，多線程對於等待第三方資源返回結果很有用。 這是因為顯式釋放 GIL 的休眠線程可以等待結果返回時喚醒。 最後，每當程序需要提供響應式界面時，多線程就是答案，即使它使用了時間片。 該程序可以與用戶交互，同時在所謂的後台進行一些繁重的計算。

### When should threading be used 
儘管存在 GIL 限制，線程在某些情況下確實很有用。 他們可以幫助：
- 構建響應式界面 
- 委派工作
- 構建多用戶應用程序

#### Building responsive interfaces
假設您要求系統通過圖形用戶界面將文件從一個文件夾複製到另一個文件夾。 任務可能會被推入後台，界面窗口會不斷被主線程刷新。 通過這種方式，您可以獲得有關整個過程進度的實時反饋。 您還可以取消操作。 與在所有工作完成之前不提供任何反饋的原始 cp 或複制 shell 命令相比，這沒有那麼煩人。

響應式界面還允許用戶同時處理多項任務。 例如，Gimp 可以讓您在處理一張圖片的同時過濾另一張圖片，因為這兩項任務是獨立的。

當嘗試實現這種響應式界面時，一個好的方法是嘗試將長時間運行的任務推送到後台，或者至少嘗試向用戶提供持續的反饋。 實現這一目標的最簡單方法是使用線程。 在這樣的場景下，它們並不是為了提高性能，而只是為了確保即使需要更長時間處理一些數據，用戶仍然可以操作界面。
如果此類後台任務執行大量 I/O 操作，您仍然可以從多核 CPU 中獲益。 那麼這是一個雙贏的局面。

#### Delegating work
如果您的進程依賴於第三方資源，線程可能真的會加速一切。
讓我們考慮一個函數的情況，該函數為文件夾中的文件編制索引並將構建的索引推送到數據庫中。 根據文件類型，函數調用不同的外部程序。 例如，一個專門處理 PDF，另一個專門處理 OpenOffice 文件。
通過執行正確的程序然後將結果存儲到數據庫中，您的函數可以為每個轉換器設置一個線程，並通過隊列將要完成的作業推送到每個轉換器，而不是按順序處理每個文件。 該函數花費的總時間將更接近於最慢轉換器的處理時間，而不是所有工作的總和。

轉換器線程可以從一開始就被初始化，負責將結果推入數據庫的代碼也可以是一個線程，它消耗隊列中的可用結果。

請注意，這種方法在某種程度上是多線程和多處理之間的混合體。 如果您將工作委託給外部進程（例如，使用 subprocess 模塊中的 run() 函數），您實際上是在多個進程中進行工作，因此這具有多進程的症狀。 但是在我們的場景中，我們是在單獨的線程中等待處理結果，所以從 Python 代碼的角度來看，它仍然主要是多線程。

線程的另一個常見用例是對外部服務執行多個 HTTP 請求。 例如，如果您想從遠程 Web API 獲取多個結果，同步執行該操作可能會花費大量時間。 如果您在發出新請求之前等待每個先前的響應，您將花費大量時間等待外部服務響應，並且每個此類請求都會增加額外的往返時間延遲。 如果您正在與一個高效的服務（例如 Google Maps API）通信，它很可能可以同時處理您的大部分請求，而不會影響單獨請求的響應時間。 然後在單獨的線程中執行多個查詢是合理的。 請記住，在執行 HTTP 請求時，大部分時間都花在從 TCP 套接字讀取數據上。 這是一個阻塞 I/O 操作，所以 CPython 會在執行 recv() C 函數時釋放 GIL。 這可以大大提高應用程序的性能。

#### Multiuser applications
線程還用作多用戶應用程序的並發基礎。 例如，Web 服務器會將用戶請求推送到一個新線程，然後變為空閒狀態，等待新請求。 擁有一個專用於每個請求的線程可以簡化很多工作，但需要開發人員注意鎖定資源。 但是，當所有共享數據都被推送到一個負責並發事務的關係數據庫中時，這就不是問題了。 因此，多用戶應用程序中的線程幾乎就像獨立的進程一樣。 他們是
在相同的過程下只是為了簡化他們在應用程序級別的管理。


使用多線程在多用戶應用程序中啟用並發比使用多處理更便宜。 單獨的進程會花費更多的資源，因為需要為每個進程加載一個新的解釋器。 另一方面，線程太多也很昂貴。 我們知道 GIL 對於 I/O 廣泛的應用程序不是這樣的問題，但總有一段時間您需要執行 Python 代碼。 由於您無法使用裸線程並行化所有應用程序部分，因此您將永遠無法利用具有多核 CPU 和單個 Python 進程的機器上的所有資源。 這就是為什麼最佳解決方案通常是多處理和多線程的混合——多個工作線程（進程）與多個線程一起運行。 幸運的是，許多 WSGI 兼容的 Web 服務器都允許這樣的設置。

#### An example of a threaded application
為了了解 Python 線程在實踐中是如何工作的，讓我們構建一個示例應用程序，它可以從實現多線程中獲得一些好處。 我們將討論您在專業實踐中可能不時遇到的一個簡單問題——進行多個並行 HTTP 查詢。 這個問題已經作為多線程的常見用例被提及。

假設我們需要使用多個查詢從某些 Web 服務中獲取數據，這些查詢無法批處理到單個大 HTTP 請求中。 作為一個現實的例子，我們將使用來自 Google Maps API 的地理編碼端點。 

地理編碼意味著簡單地將地址或地點轉換為坐標。 我們將嘗試將各種城市的預定義列表地理編碼為緯度/經度元組，並使用 python-gmaps 在標準輸出上顯示結果。 它很簡單，如下面的代碼所示：
```python
from gmaps import Geocoding
api = Geocoding
geocoded = api.geocode('Warsaw')[0]
```
由於我們的目標是展示並發問題的多線程解決方案與標準同步解決方案的比較，我們將從根本不使用線程的實現開始。 以下是循環遍歷城市列表、查詢 Google Maps API 並在文本格式的表格中顯示有關其地址和坐標的信息的程序代碼：
> chapter13/googlemap.py


##### Using one thread per item
現在是改進的時候了。 我們在 Python 中沒有做很多處理，執行時間長是與外部服務通信造成的。 我們向服務器發送一個 HTTP 請求，它計算出答案，然後我們等待響應傳回。 涉及很多 I/O，因此多線程似乎是一個可行的選擇。 我們可以在單獨的線程中同時啟動所有請求，然後等待它們接收數據。 如果我們正在與之通信的服務能夠同時處理我們的請求，我們肯定會看到性能提升。
因此，讓我們從最簡單的方法開始。 Python 通過 threading 模塊為系統線程提供乾淨且易於使用的抽象。 這個標準庫的核心是代表單個線程實例的 Thread 類。 這是 main() 函數的修改版本，它為每個要地理編碼的地方創建並啟動一個新線程，然後等待所有線程完成：
> chapter13/googlemap_thread.py

##### Using a thread pool
我們將嘗試解決的第一個問題是我們程序運行的線程的未綁定限制。 一個好的解決方案是構建一個嚴格定義大小的線程工作線程池，它將處理所有並行工作並通過一些線程安全的數據結構與工作線程通信。 通過使用這種線程池方法，我們還可以更輕鬆地解決我們剛才提到的另外兩個問題。

所以一般的想法是啟動一些預定義數量的線程，這些線程將消耗隊列中的工作項直到完成。 當沒有其他工作要做時，線程會返回，我們就可以退出程序了。 我們的結構用於與工作人員通信的一個很好的候選者是內置隊列模塊中的 Queue 類。 它是一個 FIFO（先進先出）隊列實現，與 collections 模塊中的 deque 集合非常相似，專門設計用於處理線程間通信。 這是 main() 函數的修改版本，它僅以新的 worker() 函數作為目標啟動有限數量的工作線程，並使用線程安全隊列與它們通信：
> chapter13/googlemap_queue.py

運行時間將比每個參數一個線程的情況慢，但至少現在不可能用任意長輸入耗盡所有計算資源。 此外，我們可以調整 THREAD_POOL_SIZE 參數以獲得更好的資源/時間平衡。

##### Using two-way queues
我們現在能夠解決的另一個問題是線程中輸出的潛在問題打印。 將這樣的責任留給啟動其他線程的主線程會好得多。 我們可以通過提供另一個隊列來處理這個問題，該隊列負責從我們的工作人員那裡收集結果。 這是完整的代碼，將所有內容與突出顯示的主要更改放在一起：
> chapter13/googlemap_two_way_queue.py

##### Dealing with errors and rate limiting
您在處理此類問題時可能遇到的最後一個問題是外部服務提供商強加的速率限制。 就 Google Maps API 而言，在撰寫本書時，免費和未經身份驗證的請求的官方速率限制為每秒 10 次請求和每天 2,500 次請求。 當使用多線程時，很容易耗盡這樣的限制。 由於我們尚未涵蓋任何故障場景，因此問題更加嚴重，並且在多線程 Python 代碼中處理異常比平時要復雜一些。

當客戶端超過 Google 的速率時，api.geocode() 函數將引發異常，這是個好消息。 但是這個異常是單獨拋出的，不會讓整個程序崩潰。 工作線程當然會立即退出，但主線程會等待存儲在 work_queue 上的所有任務完成（使用 work_queue.join() 調用）。 這意味著我們的工作線程應該優雅地處理可能的異常，並確保隊列中的所有項目都得到處理。 如果不進一步改進，我們可能會遇到一些工作線程崩潰並且程序永遠不會退出的情況。

讓我們對代碼做一些小改動，以便為可能發生的任何問題做好準備。 在工作線程中出現異常的情況下，我們可能會在 results_queue 隊列中放入一個錯誤實例並將當前任務標記為已完成，這與我們在沒有錯誤的情況下所做的相同。 這樣我們就可以確保主線程在等待 work_queue.join() 時不會無限期地鎖定。 然後主線程可能會檢查結果並重新引發在結果隊列中發現的任何異常。 以下是 worker() 和 main() 函數的改進版本，可以更安全地處理異常：
```python
# 原始
def worker(work_queue):
    while not work_queue.empty():
        try:
            item = work_queue.get(block=False)
        except Empty:
            break 
        else:
            fetch_place(item)
            work_queue.task_done()

# 修改
def worker(work_queue):
    while not work_queue.empty():
        try:
            item = work_queue.get(block=False)
        except Empty:
            break 
        else:
            try:

                result = fetch_place(item)
            except Exception as err:
                results_queue.put(err)
            else:
                results_queue.put(result)
            finally:
                work_queue.task_done()
```

模仿工作節奏通常被稱為節流。 PyPI 上有一些包可以讓你限制任何類型工作的速度，而且非常容易
使用。 但我們不會在這裡使用任何外部代碼。 節流是為線程引入一些鎖定原語的好機會，因此我們將嘗試從頭開始構建解決方案。

兩件重要的事情是始終用零個令牌初始化令牌桶，並且永遠不允許它填充更多可用的令牌，這些令牌按照我們的標準時間量以其速率表示，以令牌表示。 如果我們不遵循這些預防措施，我們可能會以超過速率限制的方式釋放令牌。 因為在我們的情況下，速率限制以每秒請求數表示，所以我們不需要處理任意數量的時間。 我們假設測量的基數是一秒，因此我們存儲的令牌永遠不會超過該時間段允許的請求數。 下面是允許使用令牌桶算法進行節流的類的示例實現：
> chapter13/token_bucket.py
## Multiprocessing
### The built-in multiprocessing module
#### Using process pools
#### Using multiprocessing dummy as a multithreading interface 

## Asynchoronous programming
### Cooperative multitasking and asynchronous I/O
### Python async and await keywords
### asyncio in older versions of Python
### A practical example of asynchronous programming 
### Integrating nonasynchronous code with async using futures
####  Executors and futures
#### Using executors in an event loop
