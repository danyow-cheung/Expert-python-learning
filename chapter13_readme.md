# Concurrency
並發性及其表現形式之一——並行處理——是軟件工程領域最廣泛的主題之一。 本書的大部分章節也涵蓋了廣闊的領域，幾乎所有章節都可以作為單獨一本書的大主題。 但是並發這個話題本身就非常龐大，它可以佔據幾十個位置，我們仍然無法討論它的所有重要方面和模型。

這就是為什麼我不會試圖愚弄你，並且從一開始就聲明我們幾乎不會觸及這個話題的表面。 本章的目的是展示為什麼你的應用程序可能需要並發，何時使用它，以及你可能在 Python 中使用的最重要的並發模型是什麼：
- 多線程threading
- 多processing
- 異步編程asynchronous programming

我們還將討論允許您在代碼中實現這些模型的一些語言特性、內置模塊和第三方包。 但我們不會詳細介紹它們。 將本章的內容作為您進一步研究和閱讀的切入點。 它在這裡指導您了解基本思想並幫助您決定是否真的需要並發，如果需要，哪種方法最適合您的需要。

## Why concurrency
而第二個問題的答案可能會讓一些曾經認為這是並行處理同義詞的人感到驚訝。 但並發性與並行性不同。 並發不是應用程序實現的問題，而只是程序、算法或問題的屬性。 並行性只是解決並發問題的可能方法之一。
萊斯利·蘭波特 (Leslie Lamport) 在他 1976 年發表的分佈式系統中的時間、時鐘和事件排序論文中說：
“如果兩個事件都不能因果影響另一個，則兩個事件是同時發生的。”


通過將事件外推到程序、算法或問題，如果某事物可以完全或部分分解為與順序無關的組件（單元），我們可以說它是並發的。 這些單元可以相互獨立處理，處理順序不影響最終結果。 這意味著它們也可以同時或併行處理。 如果我們以這種方式處理信息，那麼我們確實是在進行並行處理。 但這仍然不是強制性的。

## Multithreading
線程通常被開發人員認為是一個複雜的話題。 雖然這個說法完全正確，但 Python 提供了高級類和函數來簡化線程的使用。 CPython 的線程實現帶有一些不方便的細節，使它們不如其他語言有用。 對於您可能想要解決的一些集合問題，它們仍然完全沒問題，但不像 C 或 Java 那樣多。 在本節中，我們將討論 CPython 中多線程的局限性，以及 Python 線程作為可行解決方案的常見並發問題。

### What is multithreading
線程是執行線程的縮寫。 程序員可以將他或她的工作分成同時運行並共享相同內存上下文的線程。 除非你的代碼依賴第三方資源，否則多線程不會在單核處理器上加速，甚至會增加一些線程管理的開銷。 多線程將受益於多處理器或多核機器，並將在每個 CPU 內核上並行執行每個線程，從而使程序更快。 請注意，這是適用於大多數編程語言的一般規則。 在 Python 中，多核 CPU 上多線程的性能優勢有一些限制，但我們將在稍後討論。 為簡單起見，我們現在假設此陳述是正確的。


線程之間共享相同的上下文這一事實意味著您必須保護數據免受並發訪問。 如果兩個線程在沒有任何保護的情況下更新相同的數據，就會出現競爭條件。 這稱為競爭風險，由於每個線程運行的代碼對數據狀態做出錯誤假設，可能會出現意外結果。

鎖定機制有助於保護數據，線程編程一直是確保線程以安全方式訪問資源的問題。 這可能非常困難，線程編程通常會導致難以調試的錯誤，因為它們很難重現。 最糟糕的問題是，由於糟糕的代碼設計，兩個線程鎖定一個資源並試圖獲取另一個線程鎖定的資源。 他們將永遠等待彼此。 這稱為死鎖，很難調試。 可重入鎖通過確保線程不會因嘗試鎖定資源兩次而被鎖定，對此有所幫助。

多線程通常在系統內核級別得到支持。 當機器只有一個單核處理器時，系統使用時間片機制。 在這裡，CPU 從一個線程切換到另一個線程的速度如此之快，以至於有一種線程同時運行的錯覺。 這也是在處理級別完成的。 沒有多個處理單元的並行顯然是虛擬的，在這種硬件上運行多個線程不會提高性能。 無論如何，有時用
線程，即使它必須在單個內核上執行，我們稍後會看到一個可能的用例。

當您的執行環境有多個處理器或多個 CPU 內核用於配置時，一切都會改變。 即使使用時間片，進程和線程也會分佈在 CPU 之間，從而提供更快地運行程序的能力。

### How python deals with threads
與其他一些語言不同，Python 使用多個內核級線程，每個線程都可以運行任何解釋器級線程。 但是語言的標準實現——CPython——有一個主要的限制，使得線程在許多情況下不太可用。 所有訪問 Python 對象的線程都由一個全局鎖序列化。 這樣做是因為許多解釋器內部結構以及第三方 C 代碼都不是線程安全的，需要加以保護。

這種機制稱為全局解釋器鎖（GIL）
刪除 GIL 是一個偶爾出現在 python-dev 電子郵件列表中的話題，並且被開發人員多次提出。 遺憾的是，直到這個時候，還沒有人能夠提供一個合理而簡單的解決方案來讓我們擺脫這一限制。 我們極不可能很快看到這方面的任何進展。 更安全的假設是 GIL 將永遠留在 CPython 中。 所以我們需要學習如何忍受它。

這意味著，多個線程可以並行地進行 I/O 操作或執行某些第三方擴展中的 C 代碼。

對於使用外部資源或涉及 C 代碼的非純代碼塊，多線程對於等待第三方資源返回結果很有用。 這是因為顯式釋放 GIL 的休眠線程可以等待結果返回時喚醒。 最後，每當程序需要提供響應式界面時，多線程就是答案，即使它使用了時間片。 該程序可以與用戶交互，同時在所謂的後台進行一些繁重的計算。

### When should threading be used 
儘管存在 GIL 限制，線程在某些情況下確實很有用。 他們可以幫助：
- 構建響應式界面 
- 委派工作
- 構建多用戶應用程序

#### Building responsive interfaces
假設您要求系統通過圖形用戶界面將文件從一個文件夾複製到另一個文件夾。 任務可能會被推入後台，界面窗口會不斷被主線程刷新。 通過這種方式，您可以獲得有關整個過程進度的實時反饋。 您還可以取消操作。 與在所有工作完成之前不提供任何反饋的原始 cp 或複制 shell 命令相比，這沒有那麼煩人。

響應式界面還允許用戶同時處理多項任務。 例如，Gimp 可以讓您在處理一張圖片的同時過濾另一張圖片，因為這兩項任務是獨立的。

當嘗試實現這種響應式界面時，一個好的方法是嘗試將長時間運行的任務推送到後台，或者至少嘗試向用戶提供持續的反饋。 實現這一目標的最簡單方法是使用線程。 在這樣的場景下，它們並不是為了提高性能，而只是為了確保即使需要更長時間處理一些數據，用戶仍然可以操作界面。
如果此類後台任務執行大量 I/O 操作，您仍然可以從多核 CPU 中獲益。 那麼這是一個雙贏的局面。

#### Delegating work
如果您的進程依賴於第三方資源，線程可能真的會加速一切。
讓我們考慮一個函數的情況，該函數為文件夾中的文件編制索引並將構建的索引推送到數據庫中。 根據文件類型，函數調用不同的外部程序。 例如，一個專門處理 PDF，另一個專門處理 OpenOffice 文件。
通過執行正確的程序然後將結果存儲到數據庫中，您的函數可以為每個轉換器設置一個線程，並通過隊列將要完成的作業推送到每個轉換器，而不是按順序處理每個文件。 該函數花費的總時間將更接近於最慢轉換器的處理時間，而不是所有工作的總和。

轉換器線程可以從一開始就被初始化，負責將結果推入數據庫的代碼也可以是一個線程，它消耗隊列中的可用結果。

請注意，這種方法在某種程度上是多線程和多處理之間的混合體。 如果您將工作委託給外部進程（例如，使用 subprocess 模塊中的 run() 函數），您實際上是在多個進程中進行工作，因此這具有多進程的症狀。 但是在我們的場景中，我們是在單獨的線程中等待處理結果，所以從 Python 代碼的角度來看，它仍然主要是多線程。

線程的另一個常見用例是對外部服務執行多個 HTTP 請求。 例如，如果您想從遠程 Web API 獲取多個結果，同步執行該操作可能會花費大量時間。 如果您在發出新請求之前等待每個先前的響應，您將花費大量時間等待外部服務響應，並且每個此類請求都會增加額外的往返時間延遲。 如果您正在與一個高效的服務（例如 Google Maps API）通信，它很可能可以同時處理您的大部分請求，而不會影響單獨請求的響應時間。 然後在單獨的線程中執行多個查詢是合理的。 請記住，在執行 HTTP 請求時，大部分時間都花在從 TCP 套接字讀取數據上。 這是一個阻塞 I/O 操作，所以 CPython 會在執行 recv() C 函數時釋放 GIL。 這可以大大提高應用程序的性能。

#### Multiuser applications
線程還用作多用戶應用程序的並發基礎。 例如，Web 服務器會將用戶請求推送到一個新線程，然後變為空閒狀態，等待新請求。 擁有一個專用於每個請求的線程可以簡化很多工作，但需要開發人員注意鎖定資源。 但是，當所有共享數據都被推送到一個負責並發事務的關係數據庫中時，這就不是問題了。 因此，多用戶應用程序中的線程幾乎就像獨立的進程一樣。 他們是
在相同的過程下只是為了簡化他們在應用程序級別的管理。


使用多線程在多用戶應用程序中啟用並發比使用多處理更便宜。 單獨的進程會花費更多的資源，因為需要為每個進程加載一個新的解釋器。 另一方面，線程太多也很昂貴。 我們知道 GIL 對於 I/O 廣泛的應用程序不是這樣的問題，但總有一段時間您需要執行 Python 代碼。 由於您無法使用裸線程並行化所有應用程序部分，因此您將永遠無法利用具有多核 CPU 和單個 Python 進程的機器上的所有資源。 這就是為什麼最佳解決方案通常是多處理和多線程的混合——多個工作線程（進程）與多個線程一起運行。 幸運的是，許多 WSGI 兼容的 Web 服務器都允許這樣的設置。

#### An example of a threaded application
為了了解 Python 線程在實踐中是如何工作的，讓我們構建一個示例應用程序，它可以從實現多線程中獲得一些好處。 我們將討論您在專業實踐中可能不時遇到的一個簡單問題——進行多個並行 HTTP 查詢。 這個問題已經作為多線程的常見用例被提及。

假設我們需要使用多個查詢從某些 Web 服務中獲取數據，這些查詢無法批處理到單個大 HTTP 請求中。 作為一個現實的例子，我們將使用來自 Google Maps API 的地理編碼端點。 

地理編碼意味著簡單地將地址或地點轉換為坐標。 我們將嘗試將各種城市的預定義列表地理編碼為緯度/經度元組，並使用 python-gmaps 在標準輸出上顯示結果。 它很簡單，如下面的代碼所示：
```python
from gmaps import Geocoding
api = Geocoding
geocoded = api.geocode('Warsaw')[0]
```
由於我們的目標是展示並發問題的多線程解決方案與標準同步解決方案的比較，我們將從根本不使用線程的實現開始。 以下是循環遍歷城市列表、查詢 Google Maps API 並在文本格式的表格中顯示有關其地址和坐標的信息的程序代碼：
> chapter13/googlemap.py


##### Using one thread per item
現在是改進的時候了。 我們在 Python 中沒有做很多處理，執行時間長是與外部服務通信造成的。 我們向服務器發送一個 HTTP 請求，它計算出答案，然後我們等待響應傳回。 涉及很多 I/O，因此多線程似乎是一個可行的選擇。 我們可以在單獨的線程中同時啟動所有請求，然後等待它們接收數據。 如果我們正在與之通信的服務能夠同時處理我們的請求，我們肯定會看到性能提升。
因此，讓我們從最簡單的方法開始。 Python 通過 threading 模塊為系統線程提供乾淨且易於使用的抽象。 這個標準庫的核心是代表單個線程實例的 Thread 類。 這是 main() 函數的修改版本，它為每個要地理編碼的地方創建並啟動一個新線程，然後等待所有線程完成：
> chapter13/googlemap_thread.py

##### Using a thread pool
我們將嘗試解決的第一個問題是我們程序運行的線程的未綁定限制。 一個好的解決方案是構建一個嚴格定義大小的線程工作線程池，它將處理所有並行工作並通過一些線程安全的數據結構與工作線程通信。 通過使用這種線程池方法，我們還可以更輕鬆地解決我們剛才提到的另外兩個問題。

所以一般的想法是啟動一些預定義數量的線程，這些線程將消耗隊列中的工作項直到完成。 當沒有其他工作要做時，線程會返回，我們就可以退出程序了。 我們的結構用於與工作人員通信的一個很好的候選者是內置隊列模塊中的 Queue 類。 它是一個 FIFO（先進先出）隊列實現，與 collections 模塊中的 deque 集合非常相似，專門設計用於處理線程間通信。 這是 main() 函數的修改版本，它僅以新的 worker() 函數作為目標啟動有限數量的工作線程，並使用線程安全隊列與它們通信：
> chapter13/googlemap_queue.py

運行時間將比每個參數一個線程的情況慢，但至少現在不可能用任意長輸入耗盡所有計算資源。 此外，我們可以調整 THREAD_POOL_SIZE 參數以獲得更好的資源/時間平衡。

##### Using two-way queues
我們現在能夠解決的另一個問題是線程中輸出的潛在問題打印。 將這樣的責任留給啟動其他線程的主線程會好得多。 我們可以通過提供另一個隊列來處理這個問題，該隊列負責從我們的工作人員那裡收集結果。 這是完整的代碼，將所有內容與突出顯示的主要更改放在一起：
> chapter13/googlemap_two_way_queue.py

##### Dealing with errors and rate limiting
您在處理此類問題時可能遇到的最後一個問題是外部服務提供商強加的速率限制。 就 Google Maps API 而言，在撰寫本書時，免費和未經身份驗證的請求的官方速率限制為每秒 10 次請求和每天 2,500 次請求。 當使用多線程時，很容易耗盡這樣的限制。 由於我們尚未涵蓋任何故障場景，因此問題更加嚴重，並且在多線程 Python 代碼中處理異常比平時要復雜一些。

當客戶端超過 Google 的速率時，api.geocode() 函數將引發異常，這是個好消息。 但是這個異常是單獨拋出的，不會讓整個程序崩潰。 工作線程當然會立即退出，但主線程會等待存儲在 work_queue 上的所有任務完成（使用 work_queue.join() 調用）。 這意味著我們的工作線程應該優雅地處理可能的異常，並確保隊列中的所有項目都得到處理。 如果不進一步改進，我們可能會遇到一些工作線程崩潰並且程序永遠不會退出的情況。

讓我們對代碼做一些小改動，以便為可能發生的任何問題做好準備。 在工作線程中出現異常的情況下，我們可能會在 results_queue 隊列中放入一個錯誤實例並將當前任務標記為已完成，這與我們在沒有錯誤的情況下所做的相同。 這樣我們就可以確保主線程在等待 work_queue.join() 時不會無限期地鎖定。 然後主線程可能會檢查結果並重新引發在結果隊列中發現的任何異常。 以下是 worker() 和 main() 函數的改進版本，可以更安全地處理異常：
```python
# 原始
def worker(work_queue):
    while not work_queue.empty():
        try:
            item = work_queue.get(block=False)
        except Empty:
            break 
        else:
            fetch_place(item)
            work_queue.task_done()

# 修改
def worker(work_queue):
    while not work_queue.empty():
        try:
            item = work_queue.get(block=False)
        except Empty:
            break 
        else:
            try:

                result = fetch_place(item)
            except Exception as err:
                results_queue.put(err)
            else:
                results_queue.put(result)
            finally:
                work_queue.task_done()
```

模仿工作節奏通常被稱為節流。 PyPI 上有一些包可以讓你限制任何類型工作的速度，而且非常容易
使用。 但我們不會在這裡使用任何外部代碼。 節流是為線程引入一些鎖定原語的好機會，因此我們將嘗試從頭開始構建解決方案。

兩件重要的事情是始終用零個令牌初始化令牌桶，並且永遠不允許它填充更多可用的令牌，這些令牌按照我們的標準時間量以其速率表示，以令牌表示。 如果我們不遵循這些預防措施，我們可能會以超過速率限制的方式釋放令牌。 因為在我們的情況下，速率限制以每秒請求數表示，所以我們不需要處理任意數量的時間。 我們假設測量的基數是一秒，因此我們存儲的令牌永遠不會超過該時間段允許的請求數。 下面是允許使用令牌桶算法進行節流的類的示例實現：
> chapter13/token_bucket.py



## Multiprocessing
老實說，多線程具有挑戰性——我們已經在上一節中看到了這一點。 事實上，解決問題的最簡單方法只需要最少的努力。 但是以理智和安全的方式處理線程需要大量的代碼。

我們必須設置線程池和通信隊列，優雅地處理線程異常，並且在嘗試提供速率限制功能時還要關心線程安全。 幾十行代碼，並行執行一個外部庫的函數！ 我們只假設這是生產就緒的，因為外部包創建者承諾他的庫是線程安全的。 對於實際上僅適用於執行 I/O 綁定任務的解決方案來說，這聽起來像是一個高價。

允許您實現並行性的另一種方法是多處理。 不與 GIL 相互約束的獨立 Python 進程允許更好的資源利用。 這對於運行在多核處理器上的應用程序來說尤其重要，這些應用程序正在執行真正的 CPU 密集型任務。 目前，這是唯一可供 Python 開發人員（使用 CPython 解釋器）使用的內置並發解決方案，可讓您從多處理器內核中獲益。

使用多個進程的另一個優點是它們不共享內存上下文。 因此，更難破壞數據並將死鎖引入您的應用程序。 不共享內存上下文意味著您需要一些額外的努力來在不同的進程之間傳遞數據，但幸運的是，有許多好方法可以實現可靠的進程間通信。 事實上，Python 提供了一些原語，使進程之間的通信在線程之間盡可能簡單。

在任何編程語言中啟動新進程的最基本方法通常是在某個點分叉程序。 在 POSIX 系統（Unix、Mac OS 和 Linux）上，fork 是通過 os.fork() 函數在 Python 中公開的系統調用，它將創建一個新的子進程。 這兩個進程然後在分叉後自行繼續執行程序。 這是一個只分叉一次的示例腳本：
> chapter13/os_fork.py



### The built-in multiprocessing module
multiprocessing 提供了一種可移植的方式來處理進程，就好像它們是線程一樣。
該模塊包含一個與 Thread 類非常相似的 Process 類，可以在任何平台上使用：
> chapter13/process.py

 
multiprocessing.Queue 和 queue.Queue 類具有相同的接口。 唯一的區別是第一個設計用於多進程環境，而不是多線程，因此它使用不同的內部傳輸和鎖定原語。 我們已經在線程應用程序示例部分了解瞭如何將隊列與多線程一起使用，因此我們不會對多處理執行相同的操作。 用法保持完全相同，因此這樣的示例不會帶來任何新內容。

Pipe 類現在提供了一個更有趣的模式。 它是一種雙工（雙向）通信通道，在概念上與 Unix 管道非常相似。 Pipe 的接口也非常類似於來自內置套接字模塊的簡單套接字。 與原始系統管道和套接字的不同之處在於它允許您發送任何可拾取的對象（使用 pickle 模塊）而不僅僅是原始字節。 這使得進程之間的通信更加容易，因為您幾乎可以發送任何基本的 Python 類型：
> chapter13/process_pipe.py

#### Using process pools
使用多個進程而不是線程會增加一些實質性的開銷。 大多數情況下，它會增加內存佔用，因為每個進程都有自己的
獨立的內存上下文。 這意味著允許無限數量的子進程比在多線程應用程序中更成問題。

在依賴多處理以更好地利用資源的應用程序中，控制資源使用的最佳模式是以類似於使用線程池部分中針對線程描述的方式構建進程池。


multiprocessing 模塊最好的一點是它提供了一個隨時可用的 Pool 類，可以為您處理管理多個 process worker 的所有復雜性。 這個池實現大大減少了所需的樣板文件數量和與雙向通信相關的問題數量。 您也不需要手動使用 join() 方法，因為 Pool 可以用作上下文管理器（使用 with 語句）。 

#### Using multiprocessing dummy as a multithreading interface 
多處理模塊的高級抽象，例如 Pool 類，與線程模塊中提供的簡單工具相比具有很大的優勢。 但是不，這並不意味著多處理總是比多線程更好的方法。 在很多用例中，線程可能是比進程更好的解決方案。 對於需要低延遲和/或高資源效率的情況尤其如此。

這使您可以減少代碼中的樣板文件數量，並創建一個更可插入的接口。 例如，讓我們再看一下前面示例中的 main() 函數。 如果我們想讓用戶控制他想使用哪個處理後端（進程或線程），我們可以簡單地通過替換 Pool 類來實現：
> chapter13/process_thread.py
## Asynchoronous programming
在試圖解釋什麼是異步編程時，最簡單的方法是將這種方法視為類似於線程但不涉及系統調度的方法。 這意味著異步程序可以並發處理問題，但它的上下文是在內部切換的，而不是由系統調度程序切換的。

### Cooperative multitasking and asynchronous I/O
協同多任務處理是異步編程的核心。 在這種計算機多任務處理方式中，啟動上下文切換（到另一個進程或線程）不是操作系統的責任，而是每個進程在空閒時自願釋放控制以允許同時執行多個程序。 這就是為什麼它被稱為合作。 所有進程都需要合作才能順利進行多任務處理。

這種多任務模型有時被用於操作系統，但現在幾乎找不到系統級解決方案。 這是因為存在一項設計不當的服務很容易破壞整個系統穩定性的風險。 由操作系統直接管理的上下文切換的線程和進程調度現在是系統級並發的主要方法。 但是協作式多任務處理在應用程序級別仍然是一個很好的並發工具。


為避免以後混淆（由於 Python 術語），從現在開始我們將此類並發任務稱為協程。 協作式多任務處理中最重要的問題是何時釋放控制權。 在大多數異步應用程序中，I/O 操作的控制權交給了調度程序或事件循環。 無論程序是從文件系統讀取數據還是通過套接字進行通信，這樣的 I/O 操作總是與進程空閒時的一些等待時間有關。 等待時間取決於外部資源，因此這是釋放控制權的好機會，以便其他協程可以完成它們的工作，直到它們也需要等待。

這使得這種方法在行為上與 Python 中多線程的實現方式有些相似。 我們知道 GIL 序列化 Python 線程，但它也會在每次 I/O 操作時釋放。 主要區別在於Python中的線程是作為系統級線程實現的，因此操作系統可以搶占當前運行的線程並將控制權交給另一個線程
在任何時間點。 在異步編程中，任務永遠不會被主事件循環搶占。 這就是為什麼這種多任務處理方式也稱為非搶占式多任務處理。

當然，每個 Python 應用程序都在一個操作系統上運行，在這個操作系統上有其他進程競爭資源。 這意味著操作系統始終有權搶占整個進程並將控制權交給另一個進程。 但是當我們的異步應用程序重新運行時，它會從系統調度程序介入時暫停的相同位置繼續運行。這就是協程仍然被認為是非搶占式的原因。

### Python async and await keywords
async 和 await 關鍵字是 Python 異步編程中的主要構建塊。

答案是使用 asyncio.sleep()，它是 time.sleep() 的異步版本，並使用 await 關鍵字等待其結果。 我們已經在 main() 函數的第一個版本中使用了這個語句，但這只是為了提高代碼的清晰度。 它顯然沒有使我們的實現更加並發。 

### asyncio in older versions of Python
asyncio 模塊出現在 Python 3.4 中。 所以它是 Python 3.5 之前唯一認真支持異步編程的 Python 版本。 不幸的是，這兩個後續版本似乎足以引入兼容性問題。

### A practical example of asynchronous programming 
正如本章多次提到的，異步編程是處理 I/O 綁定操作的絕佳工具。 所以是時候構建一些比簡單的序列打印或異步等待更實用的東西了。

為了保持一致性，我們將嘗試處理我們在多線程和多處理的幫助下解決的相同問題。 所以我們會嘗試通過網絡連接從外部資源異步獲取一些數據。 如果我們可以使用與前面部分相同的 python-gmaps 包，那就太好了。 不幸的是，我們不能。

python-gmaps 的創建者有點懶，走了捷徑。 為了簡化開發，他選擇了一個請求包作為他選擇的 HTTP 客戶端庫。 遺憾的是，請求不支持使用 async 和 await 的異步 I/O。 還有一些其他項目旨在為requests項目提供一些並發性，但它們要么依賴Gevent（grequests，參考https://github.com/kennethreitz/grequests）要么線程/進程池執行（requests-futures， 參考 https://github.com/ross/requests-futures）。 這些都不能解決我們的問題。

### Integrating nonasynchronous code with async using futures

異步編程很棒，尤其是對於對構建可擴展應用程序感興趣的後端開發人員而言。 在實踐中，它是構建高並發服務器的最重要工具之一。

但現實是痛苦的。 許多處理 I/O 綁定問題的流行包並不意味著與異步代碼一起使用。 主要原因是：
Python 3 及其一些高級功能的採用率仍然很低 Python 初學者對各種並發概念的理解程度較低

這意味著現有的同步多線程應用程序和程序包的遷移通常是不可能的（由於架構限制）或過於昂貴。 許多項目可以從合併多任務的異步風格中獲益匪淺，但最終只有少數項目會這樣做。
這意味著現在，您在嘗試從頭開始構建異步應用程序時會遇到很多困難。 在大多數情況下，這將類似於異步編程的實際示例部分中提到的問題——不兼容的接口和 I/O 操作的非異步阻塞。

當然，當你遇到這種不兼容的情況時，你有時可以退出 await 並只同步獲取所需的資源。 但這會在您等待結果時阻止所有其他協程執行其代碼。 它在技術上是可行的，但也破壞了異步編程的所有好處。 所以最後，將異步 I/O 與同步 I/O 結合起來並不是一種選擇。 這是一種全有或全無的遊戲。

####  Executors and futures
在我們了解如何將線程或進程注入異步事件循環之前，我們將仔細研究 concurrent.futures 模塊，稍後它將成為我們所謂的解決方法的主要組成部分。

concurrent.futures 模塊中最重要的類是 Executor 和 Future。

Executor 表示可以並行處理工作項的資源池。 這看起來與多處理模塊中的類（Pool 和 dummy.Pool）的目的非常相似，但具有完全不同的接口和
語義。 它是一個不用於實例化的基類，有兩個具體實現：
- ThreadPoolExecutor：這是代表線程池的那個 
- ProcessPoolExecutor：這是代表進程池的那個
每個執行器都提供三個方法：
- submit
- map
- shutdown 



#### Using executors in an event loop
Executor.submit() 方法返回的 Future 類實例在概念上與異步編程中使用的協程非常接近。 這就是為什麼我們可以使用執行器在協作多任務處理和多處理或多線程之間進行混合。

此變通方法的核心是事件循環類的 BaseEventLoop.run_in_executor(executor, func, *args) 方法。 它允許您在由 executor 參數表示的進程或線程池中安排 func 函數的執行。 該方法最重要的一點是它返回一個新的可等待對象（可以使用 await 語句等待的對象）。 因此，多虧了這一點，您可以執行一個不是協程的阻塞函數，就像它是一個協程一樣，並且無論需要多長時間才能完成它都不會阻塞。 它只會停止正在等待此類調用結果的函數，但整個事件循環仍將繼續旋轉。
一個有用的事實是您甚至不需要創建執行程序實例。 如果將 None 作為執行器參數傳遞，ThreadPoolExecutor 類將使用默認線程數（對於 Python 3.5，它是處理器數乘以 5）。

因此，假設我們不想重寫 python-gmaps 包中導致我們頭疼的問題部分。 我們可以使用 loop.run_in_executor() 調用輕鬆地將阻塞調用推遲到單獨的線程，同時仍然將 fetch_place() 函數保留為可等待的協程：
