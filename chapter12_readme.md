# Optimization -- Some powerful Techniques
優化程序並不是一個神奇的過程。 它是通過遵循一個簡單的算法來完成的，該算法由 Stefan Schwarzer 在 Europython 2006 的原始偽代碼示例中合成：
```python
def optimize():
    """Recommended optimization"""
    assert got_architecture_right(), "fix architecture"
    assert made_code_work(bugs=None), "fix bugs"
    while code_is_too_slow():
        wbn = find_worst_bottleneck(just_guess=False,
                                    profile=True)
        is_faster = try_to_optimize(wbn,
                                    run_unit_tests=True,
                                    new_bugs=None)
        if not is_faster:
            undo_last_code_change()

```
這個例子可能不是最整潔和最清晰的例子，但幾乎涵蓋了一個有組織的優化過程的所有重要方面。 我們從中學到的主要內容是：
- 優化是一個迭代過程，並非每次迭代都會帶來更好的結果
- 主要先決條件是經驗證可在測試中正常工作的代碼
- 您應該始終專注於優化當前的應用程序瓶頸


讓您的代碼運行得更快並不是一件容易的事。 對於抽象的數學問題，解決方案當然在於選擇正確的算法和合適的數據結構。 但在那種情況下，很難提供一些可以在任何代碼中用於解決算法問題的通用提示和技巧。 當然有一些用於設計新算法的通用方法，甚至是可以應用於各種問題的元啟發式方法，但它們與語言無關，因此超出了本書的範圍。

無論如何，一些性能問題只是由某些代碼質量缺陷或應用程序使用上下文引起的。 例如，應用程序的速度可能會因以下原因而降低：
- 基本內置類型的錯誤使用
- 過於復雜
- 硬件資源使用模式與執行環境不匹配
- 等待來自第三方 API 或支持服務的響應的時間太長 在應用程序的時間關鍵部分做太多
更多時候，解決此類性能問題不需要高深的學術知識，只需要良好的軟件工藝。 工藝的很大一部分是知道何時使用適當的工具。 幸運的是，有一些眾所周知的模式和解決方案可用於處理性能問題。
在本章中，我們將討論一些流行且可重用的解決方案，這些解決方案允許您通過以下方式以非算法方式優化您的程序：
- 降低複雜性 
- 使用架構權衡 
- 緩存

## Reducing the complexity
在我們進一步深入研究優化技術之前，讓我們準確定義我們要處理的內容。 通過本章的介紹，我們知道專注於改善應用程序瓶頸對於成功優化至關重要。 瓶頸是嚴重限製程序或計算機系統容量的單個組件。 每段有性能問題的代碼的一個重要特徵是它通常只有一個瓶頸。 我們在前一章討論了一些分析技術，因此您應該已經熟悉定位和隔離這些地方所需的工具。 如果您的性能分析結果表明需要立即改進的地方很少，那麼您應該首先嘗試將每個部分視為一個單獨的組件並獨立進行優化。

當然，如果沒有明顯的瓶頸，但您的應用程序的性能仍然低於您的預期，那麼您的處境就很糟糕了。 優化過程的收益與優化瓶頸的性能影響成正比。 優化對整體執行時間或資源消耗沒有實質性貢獻的每個小組件，只會讓您在分析和優化上花費的所有時間獲得最小的收益。 如果您的應用程序似乎沒有真正的瓶頸，那麼您可能錯過了一些東西。 嘗試使用不同的分析策略或工具，或者從不同的角度（內存、I/O 操作或網絡吞吐量）來看待它。 如果這沒有幫助，你真的應該考慮修改你的軟件架構。

從那裡，優化過程有時可以理解為降低複雜性的過程。 本節通過簡化循環為這項工作提供簡單的提示。 但首先，讓我們學習如何衡量複雜性。

### Cyclomatic complexity
圈複雜度是 Thomas J. McCabe 於 1976 年開發的度量標準。由於其作者的緣故，它通常被稱為 McCabe 的複雜度。 它測量通過代碼的線性路徑的數量。 所有 if、for 和 while 循環都被計算在內以得出一個度量。


儘管圈複雜度不是判斷應用程序性能的可靠方法，但它有一個非常好的優勢。 它是一種源代碼指標，因此可以使用適當的工具進行測量。 這不能用其他表達複雜性的方式——大 O 表示法來表達。 由於可測量性，圈複雜度可能是對分析的有用補充，可以為您提供有關軟件有問題的部分的更多信息。 在考慮徹底的代碼架構重新設計時，首先要審查代碼的複雜部分。

### The big O notation

定義函數複雜性的最規範方法是大 O 表示法（請參閱 http://en.wikipedia.org/wiki/Big_O_notation）。 該指標定義算法如何受輸入數據大小的影響。 例如，算法是根據輸入數據的大小線性縮放還是二次縮放？
手動計算算法的大 O 表示法是了解其性能如何與輸入數據大小相關的最佳方法。 了解應用程序組件的複雜性使您能夠檢測並專注於真正會降低代碼速度的部分。
為了測量大 O 表示法，所有常量和低階項都被刪除，以便專注於輸入數據增長時真正重要的部分。 這個想法是嘗試將算法歸入這些類別之一，即使它是一個近似值：


例如，看一下將單個元素附加到 Python 的列表類型實例的操作。 我們知道 CPython 中的列表使用一個內部存儲過度分配的數組而不是鍊錶。 如果數組已滿，追加新元素需要分配新數組並將所有現有元素（引用）複製到內存中的新區域。 如果我們從最壞情況復雜度的角度來看，很明顯 list.append() 方法具有 O(n) 複雜度。 與鍊錶結構的典型實現相比，這有點昂貴。

在解決問題時，我們通常會了解有關輸入數據的很多細節，例如其大小或統計分佈。 在優化應用程序時，使用關於輸入數據的每一點知識總是值得的。 在這裡，另一個最壞情況下的複雜性問題開始出現。 它旨在顯示當輸入趨向於大值或無窮大時函數的限制行為，而不是為現實生活中的數據提供可靠的性能近似值。 漸近符號在定義函數的增長率時非常有用，但它無法為簡單的問題提供可靠的答案：哪個實現將花費更少的時間？ 最壞情況的複雜性會轉儲有關您的實現和數據特徵的所有這些小細節，以向您展示您的程序將如何漸進地運行。 它適用於您甚至可能不需要考慮的任意大輸入。

## Simplfying 
為了降低代碼的複雜性，數據的存儲方式是基礎。 您應該仔細選擇數據結構。 本節提供了一些示例，說明如何通過適合作業的適當數據類型來提高簡單代碼片段的性能。

### Searching in a list
由於 Python 中列表類型的實現細節，在列表中搜索特定值的操作並不便宜。 list.index() 方法的複雜度為 O(n)，其中 n 是列表元素的數量。 如果您不需要執行許多元素索引查找，那麼這種線性複雜性並不是特別糟糕，但如果需要許多此類操作，它可能會對性能產生負面影響。

如果需要快速搜索列表，可以嘗試使用 Python 標準庫中的 bisect 模塊。 該模塊中的函數主要用於插入或查找給定值的插入索引，以保持已排序序列的順序。 無論如何，它們可用於通過二分法算法有效地查找元素索引。 這是使用二進制搜索查找元素索引的函數的官方文檔中的配方：

#### Using a set instead of a list 
對相同的工作使用集合類型會更快，因為使用與 dict 類型相同的散列查找存儲的值。 此外，set 確保元素的唯一性，所以我們不需要做任何事情，只需從我們的序列對象創建一個新的集合。 換句話說，對於序列中的每個值，查看它是否已經在集合中所花費的時間將是常量：

##### Cut the external calls,reduce the workload 
部分複雜性是由對其他函數、方法和類的調用引入的。 通常，盡可能多地從循環中獲取代碼。 這對於嵌套循環來說尤為重要。 不要一遍又一遍地重新計算那些甚至在循環開始之前就可以計算的東西。 內部循環應該很緊。

## Using collections
collections 模塊提供了內置容器類型的高性能替代方案。 此模塊中可用的主要類型是：
- deque：具有額外功能的類列表類型
- defaultdict：類字典類型，內置默認工廠特性 
- namedtuple：類元組類型，為成員分配鍵

### Deque
雙端隊列是列表的另一種實現。 列表基於數組，而雙端隊列基於雙向鍊錶。 因此，當您需要將某些內容插入其中間或頭部時，雙端隊列要快得多，但當您需要訪問任意索引時，它會慢得多。

當然，由於 Python 列表類型內部數組的過度分配，並非每次 list.append() 調用都需要重新分配內存，並且該方法的平均複雜度為 O(1)。 儘管如此，在鏈接列表而不是數組上執行時，彈出和追加通常更快。 當需要在任意序列點添加元素時，情況會發生巨大變化。 因為new一個右邊的元素都需要在數組中進行移位，所以list.insert()的複雜度是O(n)。 如果您需要執行大量彈出、追加和插入操作，則用雙端隊列代替列表可能會顯著提高性能。 但是在從列表切換到雙端隊列之前，一定要確保分析您的代碼，因為一些在數組中很快的事情（例如訪問任意索引）在鍊錶中效率極低。


由於高效的 append() 和 pop() 方法在序列的兩端以相同的速度工作，deque 成為實現隊列的完美類型。 例如，如果使用雙端隊列而不是列表來實現 FIFO（先進先出）隊列，效率肯定會高得多。
### defaultdict
defaultdict 類型類似於 dict 類型，但為新鍵添加了默認工廠。 這避免了編寫額外的測試來初始化映射條目，並且比 dict.setdefault 方法更有效。

defaultdict 看起來就像是 dict 的語法糖，它只允許您編寫更短的代碼。 事實上，在失敗的鍵查找中回退到預定義值也比 dict.setdefault() 方法稍快：

差別不大，因為計算複雜度沒有改變。 dict.setdefault 方法由兩個步驟組成（鍵查找和鍵設置），這兩個步驟的複雜度都是 O(1)，正如我們在第 2 章“語法最佳實踐——類級以下的字典”部分中看到的那樣。 沒有辦法讓複雜度等級低於 O(1)。 但在某些情況下，它無疑更快，值得了解，因為在優化關鍵代碼部分時，每一個小的速度改進都很重要。
defaultdict 類型將工廠作為參數，因此可以與構造函數不帶參數的內置類型或類一起使用。 下面是官方文檔中的一個示例，展示瞭如何使用 defaultdict 進行計數：
```python
s = 'mississippi'
d = defaultdict(int)
for k in s:
    d[k]+=1 
list(d.items())
```

### namedtuple
namedtuple 是一個類工廠，它接受一個類型名稱和一個屬性列表，並從中創建一個類。 然後該類可用於實例化類似元組的對象並為其元素提供訪問器：

與需要一些樣板代碼來初始化值的自定義類相比，它可用於創建更易於編寫的記錄。 另一方面，它基於元組，因此通過索引訪問其元素非常快。 可以對生成的類進行子類化以添加更多操作。
使用 namedtuple 而不是其他數據類型的好處一開始可能並不明顯。 主要優點是它比普通元組更易於使用、理解和解釋。 元組索引不攜帶任何語義，因此通過屬性訪問元組元素也很棒。 但是，您可以從具有 O(1) 平均複雜度的 get/set 操作的字典中獲得相同的好處。
第一個性能上的優勢，namedtuple還是tuple的味道。 這意味著它是不可變的，因此底層數組存儲是根據需要的大小精確分配的。 另一方面，字典需要使用內部哈希表的過度分配來確保 get/set 操作的平均複雜度較低。 因此，namedtuple 在內存效率方面勝過 dict。


namedtuple 基於元組的事實也可能對性能有益。 它的元素可以通過整數索引訪問，就像在其他兩個簡單的序列對象——列表和元組中一樣。 這個操作既簡單又快速。 對於 dict 或自定義類實例（也使用字典來存儲屬性），元素訪問需要哈希表查找。 它經過高度優化以確保獨立於集合大小的良好性能，但提到的 O(1) 複雜度實際上只是平均複雜度。 這
字典中設置/獲取操作的實際分攤最壞情況復雜度為 O(n)。 在給定時刻執行此類操作時的實際工作量取決於集合大小及其歷史。 因此，在對性能至關重要的代碼部分，有時使用列表或元組而不是字典可能是明智的。 這只是因為它們在性能方面更具可預測性。

在這種情況下，namedtuple 是一個很好的類型，它結合了字典和元組的優點：
- 在可讀性更重要的部分，屬性訪問可能是首選
- 在性能關鍵部分，可以通過其索引訪問元素
## Using architectural trade-offs
當無法通過降低複雜性或選擇合適的數據結構來進一步改進代碼時，一個好的方法可能是考慮做一些權衡。 如果我們審查用戶問題並定義對他們來說真正重要的是什麼，我們就可以放寬一些應用程序要求。 通常可以通過以下方式提高性能：
- 用啟發式算法和近似算法代替精確解算法
- 將一些工作推遲到延遲任務隊列
- 使用概率數據結構

### Using heuristics and approximation algorithms
一些算法問題根本沒有可以在用戶可接受的時間內運行的最先進的解決方案。 例如，考慮一個處理一些複雜優化問題的程序，例如旅行商問題 (TSP) 或車輛路徑問題 (VRP)。 這兩個問題都是組合優化中的 NP-hard 問題。 此類具有低複雜性的問題的確切算法尚不清楚。 這意味著實際上可以解決的問題的規模是非常有限的。 對於非常大的輸入，它不太可能在任何用戶都能接受的時間內提供精確的解決方案。

幸運的是，用戶很可能對最好的解決方案不感興趣，而是對足夠好的解決方案感興趣，並且可以及時獲得。 因此，只要啟發式或近似算法提供可接受的結果質量，就可以使用它們：


啟發式的另一個好處是，對於您需要解決的每個新問題，它們並不總是需要從頭開始構建。 他們的高級版本，稱為元啟發式，提供解決非特定問題數學優化問題的策略，因此可以應用於許多情況。 一些流行的元啟發式算法包括：
- 模擬退火
- 遺傳算法
- 禁忌搜索
- 蟻群優化進化計算

### Using task queues an delayed processing
有時候，不是做的多，而是在對的時間做。 一個很好的例子是在 Web 應用程序中發送電子郵件。 在那種情況下，響應時間的增加不一定是您實施的結果。 響應時間可能由某些第三方服務決定，例如電子郵件服務器。 如果您的應用程序大部分時間都花在等待其他服務的回复上，您能否優化您的應用程序？

答案是：是和否。 如果您無法控製作為處理時間主要貢獻者的服務，並且沒有其他更快的解決方案可以使用，那麼您當然無法進一步加快速度。 您不能簡單地及時跳過以獲得您正在等待的回复。 


儘管有一些優秀且經過實戰檢驗的工具，但您應該始終仔細考慮您對任務隊列的處理方法。 絕對不是每一種工作都應該在隊列中處理。 他們擅長解決一些類型的問題，但也會引入大量新問題：
- 系統架構的複雜性增加 
- 處理多次交付 
- 更多服務需要維護和監控
- 更大的處理延遲 
- 更困難的日誌記錄

### Using probabilistic data structures
概率數據結構是一種旨在存儲值集合的結構，其存儲方式允許您在時間或資源限制內回答某些特定問題，而其他數據結構則無法做到這一點。 最重要的事實是答案很可能是真實的或者是真實值的近似值。 但是，可以很容易地估計出正確答案的概率或其準確性。 因此，儘管並不總是給出正確答案，但如果我們接受某種程度的錯誤，它仍然有用。


HyperLogLog（參考 https://en.wikipedia.org/wiki/HyperLogLog）是一種近似多重集中不同元素數量的算法。 對於普通集合，您需要存儲每個元素，這對於非常大的數據集來說可能非常不切實際。 HLL 不同於將集合實現為編程數據結構的經典方法。 在不深入研究實現細節的情況下，假設它只專注於提供集合基數的近似值。 因此，永遠不會存儲實際值。 它們不能被檢索、迭代和測試成員資格。 HyperLogLog 用準確性和正確性來換取時間複雜度和內存大小。 例如，HLL 的 Redis 實現僅佔用 12k 字節，標準錯誤率為 0.81%，並且沒有實際的集合大小限制。

使用概率數據結構是解決性能問題的一種非常有趣的方法。 在大多數情況下，它是為了更快的處理或更好的資源使用而犧牲一些準確性或正確性。 但它並不總是需要那樣。 概率數據結構經常用於鍵/值存儲系統以加速鍵查找。 在此類系統中使用的一種流行技術稱為近似成員查詢 (AMQ)。 一種可用於此目的的有趣數據結構是布隆過濾器（請參閱
## Caching
當您的某些應用程序函數計算時間過長時，需要考慮的有用技術是緩存。 緩存只不過是保存一個返回值以供將來參考。 只要滿足以下條件，就可以緩存運行成本高昂的函數或方法的結果：

- 該函數是確定性的，給定相同的輸入，結果每次都具有相同的值
- 函數的返回值在一段時間內繼續有用和有效（非確定性）

換句話說，確定性函數總是為同一組參數返回相同的結果，而非確定性函數返回的結果可能隨時間變化。 這種方法通常會大大減少計算時間，並讓您節省大量計算機資源。
任何緩存解決方案最重要的要求是擁有一個存儲，使您可以比計算它們更快地檢索保存的值。 緩存的良好候選者通常是：
- 查詢數據庫的可調用結果
- 來自呈現靜態值的可調用項的結果，例如文件內容、Web 請求或 PDF 呈現
- 來自執行複雜計算的確定性可調用項的結果
- 跟踪具有到期時間的值的全局映射，例如 Web 會話對象
- 需要經常快速訪問的結果


緩存的另一個重要用例是保存來自通過 Web 提供的第三方 API 的結果。 這可以通過切斷網絡延遲來極大地提高應用程序性能，但如果您為此類 API 的每個請求付費，也可以節省資金。

根據您的應用程序架構，緩存可以通過多種方式實現，並且具有不同的複雜程度。 提供緩存的方法有很多種，複雜的應用程序可以在應用程序體系結構堆棧的不同級別上使用不同的方法。 有時緩存可能與保存在進程內存中的單個全局數據結構（通常是字典）一樣簡單。 在其他情況下，您可能希望設置一個專用的緩存服務，該服務將在精心定制的硬件上運行。 本節將為您提供有關最流行的緩存方法的基本信息，並指導您了解常見的用例和常見的陷阱。

### Deterministic caching
### Nondeterminstic caching
### Cache services 
#### Memcached 
