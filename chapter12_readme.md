# Optimization -- Some powerful Techniques
優化程序並不是一個神奇的過程。 它是通過遵循一個簡單的算法來完成的，該算法由 Stefan Schwarzer 在 Europython 2006 的原始偽代碼示例中合成：
```python
def optimize():
    """Recommended optimization"""
    assert got_architecture_right(), "fix architecture"
    assert made_code_work(bugs=None), "fix bugs"
    while code_is_too_slow():
        wbn = find_worst_bottleneck(just_guess=False,
                                    profile=True)
        is_faster = try_to_optimize(wbn,
                                    run_unit_tests=True,
                                    new_bugs=None)
        if not is_faster:
            undo_last_code_change()

```
這個例子可能不是最整潔和最清晰的例子，但幾乎涵蓋了一個有組織的優化過程的所有重要方面。 我們從中學到的主要內容是：
- 優化是一個迭代過程，並非每次迭代都會帶來更好的結果
- 主要先決條件是經驗證可在測試中正常工作的代碼
- 您應該始終專注於優化當前的應用程序瓶頸


讓您的代碼運行得更快並不是一件容易的事。 對於抽象的數學問題，解決方案當然在於選擇正確的算法和合適的數據結構。 但在那種情況下，很難提供一些可以在任何代碼中用於解決算法問題的通用提示和技巧。 當然有一些用於設計新算法的通用方法，甚至是可以應用於各種問題的元啟發式方法，但它們與語言無關，因此超出了本書的範圍。

無論如何，一些性能問題只是由某些代碼質量缺陷或應用程序使用上下文引起的。 例如，應用程序的速度可能會因以下原因而降低：
- 基本內置類型的錯誤使用
- 過於復雜
- 硬件資源使用模式與執行環境不匹配
- 等待來自第三方 API 或支持服務的響應的時間太長 在應用程序的時間關鍵部分做太多
更多時候，解決此類性能問題不需要高深的學術知識，只需要良好的軟件工藝。 工藝的很大一部分是知道何時使用適當的工具。 幸運的是，有一些眾所周知的模式和解決方案可用於處理性能問題。
在本章中，我們將討論一些流行且可重用的解決方案，這些解決方案允許您通過以下方式以非算法方式優化您的程序：
- 降低複雜性 
- 使用架構權衡 
- 緩存

## Reducing the complexity
在我們進一步深入研究優化技術之前，讓我們準確定義我們要處理的內容。 通過本章的介紹，我們知道專注於改善應用程序瓶頸對於成功優化至關重要。 瓶頸是嚴重限製程序或計算機系統容量的單個組件。 每段有性能問題的代碼的一個重要特徵是它通常只有一個瓶頸。 我們在前一章討論了一些分析技術，因此您應該已經熟悉定位和隔離這些地方所需的工具。 如果您的性能分析結果表明需要立即改進的地方很少，那麼您應該首先嘗試將每個部分視為一個單獨的組件並獨立進行優化。

當然，如果沒有明顯的瓶頸，但您的應用程序的性能仍然低於您的預期，那麼您的處境就很糟糕了。 優化過程的收益與優化瓶頸的性能影響成正比。 優化對整體執行時間或資源消耗沒有實質性貢獻的每個小組件，只會讓您在分析和優化上花費的所有時間獲得最小的收益。 如果您的應用程序似乎沒有真正的瓶頸，那麼您可能錯過了一些東西。 嘗試使用不同的分析策略或工具，或者從不同的角度（內存、I/O 操作或網絡吞吐量）來看待它。 如果這沒有幫助，你真的應該考慮修改你的軟件架構。

從那裡，優化過程有時可以理解為降低複雜性的過程。 本節通過簡化循環為這項工作提供簡單的提示。 但首先，讓我們學習如何衡量複雜性。

### Cyclomatic complexity
圈複雜度是 Thomas J. McCabe 於 1976 年開發的度量標準。由於其作者的緣故，它通常被稱為 McCabe 的複雜度。 它測量通過代碼的線性路徑的數量。 所有 if、for 和 while 循環都被計算在內以得出一個度量。


儘管圈複雜度不是判斷應用程序性能的可靠方法，但它有一個非常好的優勢。 它是一種源代碼指標，因此可以使用適當的工具進行測量。 這不能用其他表達複雜性的方式——大 O 表示法來表達。 由於可測量性，圈複雜度可能是對分析的有用補充，可以為您提供有關軟件有問題的部分的更多信息。 在考慮徹底的代碼架構重新設計時，首先要審查代碼的複雜部分。

### The big O notation

定義函數複雜性的最規範方法是大 O 表示法（請參閱 http://en.wikipedia.org/wiki/Big_O_notation）。 該指標定義算法如何受輸入數據大小的影響。 例如，算法是根據輸入數據的大小線性縮放還是二次縮放？
手動計算算法的大 O 表示法是了解其性能如何與輸入數據大小相關的最佳方法。 了解應用程序組件的複雜性使您能夠檢測並專注於真正會降低代碼速度的部分。
為了測量大 O 表示法，所有常量和低階項都被刪除，以便專注於輸入數據增長時真正重要的部分。 這個想法是嘗試將算法歸入這些類別之一，即使它是一個近似值：


例如，看一下將單個元素附加到 Python 的列表類型實例的操作。 我們知道 CPython 中的列表使用一個內部存儲過度分配的數組而不是鍊錶。 如果數組已滿，追加新元素需要分配新數組並將所有現有元素（引用）複製到內存中的新區域。 如果我們從最壞情況復雜度的角度來看，很明顯 list.append() 方法具有 O(n) 複雜度。 與鍊錶結構的典型實現相比，這有點昂貴。

在解決問題時，我們通常會了解有關輸入數據的很多細節，例如其大小或統計分佈。 在優化應用程序時，使用關於輸入數據的每一點知識總是值得的。 在這裡，另一個最壞情況下的複雜性問題開始出現。 它旨在顯示當輸入趨向於大值或無窮大時函數的限制行為，而不是為現實生活中的數據提供可靠的性能近似值。 漸近符號在定義函數的增長率時非常有用，但它無法為簡單的問題提供可靠的答案：哪個實現將花費更少的時間？ 最壞情況的複雜性會轉儲有關您的實現和數據特徵的所有這些小細節，以向您展示您的程序將如何漸進地運行。 它適用於您甚至可能不需要考慮的任意大輸入。

## Simplfying 
為了降低代碼的複雜性，數據的存儲方式是基礎。 您應該仔細選擇數據結構。 本節提供了一些示例，說明如何通過適合作業的適當數據類型來提高簡單代碼片段的性能。

### Searching in a list
由於 Python 中列表類型的實現細節，在列表中搜索特定值的操作並不便宜。 list.index() 方法的複雜度為 O(n)，其中 n 是列表元素的數量。 如果您不需要執行許多元素索引查找，那麼這種線性複雜性並不是特別糟糕，但如果需要許多此類操作，它可能會對性能產生負面影響。

如果需要快速搜索列表，可以嘗試使用 Python 標準庫中的 bisect 模塊。 該模塊中的函數主要用於插入或查找給定值的插入索引，以保持已排序序列的順序。 無論如何，它們可用於通過二分法算法有效地查找元素索引。 這是使用二進制搜索查找元素索引的函數的官方文檔中的配方：

#### Using a set instead of a list 
對相同的工作使用集合類型會更快，因為使用與 dict 類型相同的散列查找存儲的值。 此外，set 確保元素的唯一性，所以我們不需要做任何事情，只需從我們的序列對象創建一個新的集合。 換句話說，對於序列中的每個值，查看它是否已經在集合中所花費的時間將是常量：

##### Cut the external calls,reduce the workload 
部分複雜性是由對其他函數、方法和類的調用引入的。 通常，盡可能多地從循環中獲取代碼。 這對於嵌套循環來說尤為重要。 不要一遍又一遍地重新計算那些甚至在循環開始之前就可以計算的東西。 內部循環應該很緊。

## Using collections
collections 模塊提供了內置容器類型的高性能替代方案。 此模塊中可用的主要類型是：
- deque：具有額外功能的類列表類型
- defaultdict：類字典類型，內置默認工廠特性 
- namedtuple：類元組類型，為成員分配鍵

### Deque
雙端隊列是列表的另一種實現。 列表基於數組，而雙端隊列基於雙向鍊錶。 因此，當您需要將某些內容插入其中間或頭部時，雙端隊列要快得多，但當您需要訪問任意索引時，它會慢得多。

當然，由於 Python 列表類型內部數組的過度分配，並非每次 list.append() 調用都需要重新分配內存，並且該方法的平均複雜度為 O(1)。 儘管如此，在鏈接列表而不是數組上執行時，彈出和追加通常更快。 當需要在任意序列點添加元素時，情況會發生巨大變化。 因為new一個右邊的元素都需要在數組中進行移位，所以list.insert()的複雜度是O(n)。 如果您需要執行大量彈出、追加和插入操作，則用雙端隊列代替列表可能會顯著提高性能。 但是在從列表切換到雙端隊列之前，一定要確保分析您的代碼，因為一些在數組中很快的事情（例如訪問任意索引）在鍊錶中效率極低。


由於高效的 append() 和 pop() 方法在序列的兩端以相同的速度工作，deque 成為實現隊列的完美類型。 例如，如果使用雙端隊列而不是列表來實現 FIFO（先進先出）隊列，效率肯定會高得多。
### defaultdict
defaultdict 類型類似於 dict 類型，但為新鍵添加了默認工廠。 這避免了編寫額外的測試來初始化映射條目，並且比 dict.setdefault 方法更有效。

defaultdict 看起來就像是 dict 的語法糖，它只允許您編寫更短的代碼。 事實上，在失敗的鍵查找中回退到預定義值也比 dict.setdefault() 方法稍快：

差別不大，因為計算複雜度沒有改變。 dict.setdefault 方法由兩個步驟組成（鍵查找和鍵設置），這兩個步驟的複雜度都是 O(1)，正如我們在第 2 章“語法最佳實踐——類級以下的字典”部分中看到的那樣。 沒有辦法讓複雜度等級低於 O(1)。 但在某些情況下，它無疑更快，值得了解，因為在優化關鍵代碼部分時，每一個小的速度改進都很重要。
defaultdict 類型將工廠作為參數，因此可以與構造函數不帶參數的內置類型或類一起使用。 下面是官方文檔中的一個示例，展示瞭如何使用 defaultdict 進行計數：
```python
s = 'mississippi'
d = defaultdict(int)
for k in s:
    d[k]+=1 
list(d.items())
```

### namedtuple
namedtuple 是一個類工廠，它接受一個類型名稱和一個屬性列表，並從中創建一個類。 然後該類可用於實例化類似元組的對象並為其元素提供訪問器：

與需要一些樣板代碼來初始化值的自定義類相比，它可用於創建更易於編寫的記錄。 另一方面，它基於元組，因此通過索引訪問其元素非常快。 可以對生成的類進行子類化以添加更多操作。
使用 namedtuple 而不是其他數據類型的好處一開始可能並不明顯。 主要優點是它比普通元組更易於使用、理解和解釋。 元組索引不攜帶任何語義，因此通過屬性訪問元組元素也很棒。 但是，您可以從具有 O(1) 平均複雜度的 get/set 操作的字典中獲得相同的好處。
第一個性能上的優勢，namedtuple還是tuple的味道。 這意味著它是不可變的，因此底層數組存儲是根據需要的大小精確分配的。 另一方面，字典需要使用內部哈希表的過度分配來確保 get/set 操作的平均複雜度較低。 因此，namedtuple 在內存效率方面勝過 dict。


namedtuple 基於元組的事實也可能對性能有益。 它的元素可以通過整數索引訪問，就像在其他兩個簡單的序列對象——列表和元組中一樣。 這個操作既簡單又快速。 對於 dict 或自定義類實例（也使用字典來存儲屬性），元素訪問需要哈希表查找。 它經過高度優化以確保獨立於集合大小的良好性能，但提到的 O(1) 複雜度實際上只是平均複雜度。 這
字典中設置/獲取操作的實際分攤最壞情況復雜度為 O(n)。 在給定時刻執行此類操作時的實際工作量取決於集合大小及其歷史。 因此，在對性能至關重要的代碼部分，有時使用列表或元組而不是字典可能是明智的。 這只是因為它們在性能方面更具可預測性。

在這種情況下，namedtuple 是一個很好的類型，它結合了字典和元組的優點：
- 在可讀性更重要的部分，屬性訪問可能是首選
- 在性能關鍵部分，可以通過其索引訪問元素
## Using architectural trade-offs
當無法通過降低複雜性或選擇合適的數據結構來進一步改進代碼時，一個好的方法可能是考慮做一些權衡。 如果我們審查用戶問題並定義對他們來說真正重要的是什麼，我們就可以放寬一些應用程序要求。 通常可以通過以下方式提高性能：
- 用啟發式算法和近似算法代替精確解算法
- 將一些工作推遲到延遲任務隊列
- 使用概率數據結構

### Using heuristics and approximation algorithms
一些算法問題根本沒有可以在用戶可接受的時間內運行的最先進的解決方案。 例如，考慮一個處理一些複雜優化問題的程序，例如旅行商問題 (TSP) 或車輛路徑問題 (VRP)。 這兩個問題都是組合優化中的 NP-hard 問題。 此類具有低複雜性的問題的確切算法尚不清楚。 這意味著實際上可以解決的問題的規模是非常有限的。 對於非常大的輸入，它不太可能在任何用戶都能接受的時間內提供精確的解決方案。

幸運的是，用戶很可能對最好的解決方案不感興趣，而是對足夠好的解決方案感興趣，並且可以及時獲得。 因此，只要啟發式或近似算法提供可接受的結果質量，就可以使用它們：


啟發式的另一個好處是，對於您需要解決的每個新問題，它們並不總是需要從頭開始構建。 他們的高級版本，稱為元啟發式，提供解決非特定問題數學優化問題的策略，因此可以應用於許多情況。 一些流行的元啟發式算法包括：
- 模擬退火
- 遺傳算法
- 禁忌搜索
- 蟻群優化進化計算

### Using task queues an delayed processing
有時候，不是做的多，而是在對的時間做。 一個很好的例子是在 Web 應用程序中發送電子郵件。 在那種情況下，響應時間的增加不一定是您實施的結果。 響應時間可能由某些第三方服務決定，例如電子郵件服務器。 如果您的應用程序大部分時間都花在等待其他服務的回复上，您能否優化您的應用程序？

答案是：是和否。 如果您無法控製作為處理時間主要貢獻者的服務，並且沒有其他更快的解決方案可以使用，那麼您當然無法進一步加快速度。 您不能簡單地及時跳過以獲得您正在等待的回复。 


儘管有一些優秀且經過實戰檢驗的工具，但您應該始終仔細考慮您對任務隊列的處理方法。 絕對不是每一種工作都應該在隊列中處理。 他們擅長解決一些類型的問題，但也會引入大量新問題：
- 系統架構的複雜性增加 
- 處理多次交付 
- 更多服務需要維護和監控
- 更大的處理延遲 
- 更困難的日誌記錄

### Using probabilistic data structures
概率數據結構是一種旨在存儲值集合的結構，其存儲方式允許您在時間或資源限制內回答某些特定問題，而其他數據結構則無法做到這一點。 最重要的事實是答案很可能是真實的或者是真實值的近似值。 但是，可以很容易地估計出正確答案的概率或其準確性。 因此，儘管並不總是給出正確答案，但如果我們接受某種程度的錯誤，它仍然有用。


HyperLogLog（參考 https://en.wikipedia.org/wiki/HyperLogLog）是一種近似多重集中不同元素數量的算法。 對於普通集合，您需要存儲每個元素，這對於非常大的數據集來說可能非常不切實際。 HLL 不同於將集合實現為編程數據結構的經典方法。 在不深入研究實現細節的情況下，假設它只專注於提供集合基數的近似值。 因此，永遠不會存儲實際值。 它們不能被檢索、迭代和測試成員資格。 HyperLogLog 用準確性和正確性來換取時間複雜度和內存大小。 例如，HLL 的 Redis 實現僅佔用 12k 字節，標準錯誤率為 0.81%，並且沒有實際的集合大小限制。

使用概率數據結構是解決性能問題的一種非常有趣的方法。 在大多數情況下，它是為了更快的處理或更好的資源使用而犧牲一些準確性或正確性。 但它並不總是需要那樣。 概率數據結構經常用於鍵/值存儲系統以加速鍵查找。 在此類系統中使用的一種流行技術稱為近似成員查詢 (AMQ)。 一種可用於此目的的有趣數據結構是布隆過濾器（請參閱
## Caching
當您的某些應用程序函數計算時間過長時，需要考慮的有用技術是緩存。 緩存只不過是保存一個返回值以供將來參考。 只要滿足以下條件，就可以緩存運行成本高昂的函數或方法的結果：

- 該函數是確定性的，給定相同的輸入，結果每次都具有相同的值
- 函數的返回值在一段時間內繼續有用和有效（非確定性）

換句話說，確定性函數總是為同一組參數返回相同的結果，而非確定性函數返回的結果可能隨時間變化。 這種方法通常會大大減少計算時間，並讓您節省大量計算機資源。
任何緩存解決方案最重要的要求是擁有一個存儲，使您可以比計算它們更快地檢索保存的值。 緩存的良好候選者通常是：
- 查詢數據庫的可調用結果
- 來自呈現靜態值的可調用項的結果，例如文件內容、Web 請求或 PDF 呈現
- 來自執行複雜計算的確定性可調用項的結果
- 跟踪具有到期時間的值的全局映射，例如 Web 會話對象
- 需要經常快速訪問的結果


緩存的另一個重要用例是保存來自通過 Web 提供的第三方 API 的結果。 這可以通過切斷網絡延遲來極大地提高應用程序性能，但如果您為此類 API 的每個請求付費，也可以節省資金。

根據您的應用程序架構，緩存可以通過多種方式實現，並且具有不同的複雜程度。 提供緩存的方法有很多種，複雜的應用程序可以在應用程序體系結構堆棧的不同級別上使用不同的方法。 有時緩存可能與保存在進程內存中的單個全局數據結構（通常是字典）一樣簡單。 在其他情況下，您可能希望設置一個專用的緩存服務，該服務將在精心定制的硬件上運行。 本節將為您提供有關最流行的緩存方法的基本信息，並指導您了解常見的用例和常見的陷阱。

### Deterministic caching
確定性函數是最簡單和最安全的緩存用例。 如果給定完全相同的輸入，確定性函數總是返回相同的值，因此通常您可以無限期地存儲它們的結果。 唯一的限制是用於緩存的存儲大小。 緩存此類結果的最簡單方法是將它們放入進程內存中，因為它通常是從中檢索數據最快的地方。 這種技術通常稱為記憶化。

當然，我們的 memoize() 裝飾器的實現並不完美。 它對於這個簡單的例子來說效果很好，但它絕對不是一個可重用的軟件。 如果您需要記憶具有多個參數的函數或想要限制緩存的大小，您需要更通用的東西。 幸運的是，Python 標準庫提供了一個非常簡單且可重用的實用程序，當您需要在內存中緩存確定性函數的結果時，可以在大多數情況下使用它。Itisthelru_cache(maxsize, typed) 來自 functools 模塊的裝飾器。 名字來源於LRU緩存，代表last recently used。 附加參數允許更好地控制記憶行為：
```python
@lru_cache(None)
def func():
    pass 
```
### Nondeterminstic caching
非確定性函數的緩存比記憶更棘手。 由於這樣一個函數的每次執行都可能給出不同的結果，因此通常不可能在任意長的時間內使用以前的值。 您需要做的是決定緩存值在多長時間內可以被視為有效。 經過一段定義的時間後，存儲的結果被認為是陳舊的，需要用新值刷新緩存。
通常是緩存主題的非確定性函數通常依賴於一些難以在應用程序代碼內部跟踪的外部狀態。 組件的典型示例是：
- 關係數據庫和通常任何類型的結構化數據存儲引擎
- 可通過網絡連接訪問的第三方服務（Web API） 文件系統

因此，換句話說，當您臨時使用預先計算的結果而不確定它們表示的狀態是否與其他系統組件（通常是支持服務）的狀態一致時，在任何情況下都會使用非確定性緩存。

請注意，這樣的緩存實現顯然是一種權衡。 因此，它在某種程度上與我們在使用架構權衡部分中介紹的技術相關。 如果您每次都放棄運行部分代碼，而是使用過去保存的結果，那麼您就有使用過時數據或代表系統不一致狀態的數據的風險。 這樣，您就可以用正確性和/或完整性來換取速度和性能。

當然，只要與緩存交互所花費的時間少於函數所花費的時間，這樣的緩存就是高效的。 如果簡單地重新計算值更快，一定要這樣做！ 這就是為什麼只有在值得的情況下才必須設置緩存； 正確設置它是有代價的。

緩存的實際內容通常是與系統其他組件交互的全部結果。 如果你想在與數據庫通信時節省時間和資源，緩存昂貴的查詢是值得的。 如果你想減少 I/O 操作的數量，你可能想要緩存內容
經常訪問的文件（例如配置文件）。
緩存非確定性函數的技術實際上與緩存確定性函數的技術非常相似。 最顯著的區別是它們通常需要根據年齡使緩存值無效的選項。 這意味著 functools 模塊中的 lru_cache() 裝飾器在這種情況下的使用非常有限。 擴展此功能以提供過期功能應該不難，但我會把它留給您作為練習。

### Cache services 
我們說過可以使用本地進程內存來實現非確定性緩存，但實際上很少這樣做。 這是因為本地進程內存作為大型應用程序中緩存存儲的效用非常有限。
如果您遇到非確定性緩存是您解決性能問題的首選解決方案的情況，您通常需要更多的東西。 通常，當您需要同時為多個用戶提供數據或服務時，非確定性緩存是您必須擁有的解決方案。 如果這是真的，那麼您遲早需要確保可以同時為用戶提供服務。 雖然本地內存提供了一種在多個線程之間共享數據的方法，但它可能不是每個應用程序的最佳並發模型。 它的擴展性不好，因此您最終需要將您的應用程序作為多個進程運行。


後續請求的一致性是一個嚴重的問題（尤其是）對於具有分佈式後端的 Web 應用程序。 在復雜的分佈式系統中，很難確保同一台機器上託管的同一進程始終一致地為用戶提供服務。 這在某種程度上當然是可行的，但是一旦你解決了那個問題，就會彈出十個其他問題。

如果您正在製作一個需要為多個並髮用戶提供服務的應用程序，那麼處理非確定性緩存的最佳方法是為此使用一些專用服務。 使用 Redis 或 Memcached 等工具，您可以讓所有應用程序進程共享相同的緩存結果。 這既減少了寶貴計算資源的使用，又避免了因擁有多個獨立且不一致的緩存而導致的問題。

#### Memcached 
如果您想認真對待緩存，Memcached 是一個非常流行且久經考驗的解決方案。 此緩存服務器由大型應用程序使用，例如
Facebook 或維基百科來擴展他們的網站。 在簡單的緩存功能中，它具有集群功能，可以立即建立高效的分佈式緩存系統。
該工具基於 Unix，但可以從任何平台和多種語言驅動。 有許多 Python 客戶端彼此之間略有不同，但基本用法通常是相同的。 與 Memcached 的最簡單交互幾乎總是包含三種方法：
- set(key,value)
- get(key)
- delete(key)

使用基於鍵/值存儲原則的每個緩存服務時，另一個非常常見的問題是如何選擇鍵名。
對於緩存具有基本參數的簡單函數調用的情況，問題通常很簡單。 您可以將函數名稱及其參數轉換為字符串並將它們連接在一起。 如果您在應用程序的許多部分使用緩存，您唯一需要關心的是確保為不同功能創建的鍵之間沒有衝突。
更有問題的情況是緩存函數具有由字典或自定義類組成的複雜參數。 在這種情況下，您需要找到一種方法，以一致的方式將此類調用簽名轉換為緩存密鑰。

最後一個問題是，與許多其他緩存服務一樣，Memcached 不喜歡很長的鍵字符串。 通常，越短越好。 長密鑰可能會降低性能或不符合硬編碼的服務限制。 例如，如果您緩存整個 SQL 查詢，查詢字符串本身通常是可以用作鍵的良好唯一標識符。 但另一方面，複雜的查詢通常太長而無法存儲在典型的緩存服務（如 Memcached）中。 一種常見的做法是計算 MD5、SHA 或任何其他哈希函數並將其用作緩存鍵。 Python 標準庫有一個 hashlib 模塊，它提供了一些流行的哈希算法的實現。
請記住，計算哈希值是有代價的。 但是，有時它是唯一可行的解決方案。 在處理創建緩存鍵時需要使用的複雜類型時，它也是一種非常有用的技術。 使用散列函數時要注意的一件重要事情是散列衝突。 沒有保證永遠不會發生碰撞的哈希函數，因此請務必了解概率並註意此類風險。
